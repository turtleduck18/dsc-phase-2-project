{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project Submission\n",
    "\n",
    "Please fill out:\n",
    "* Student name: \n",
    "* Student pace: self paced / part time / full time\n",
    "* Scheduled project review date/time: \n",
    "* Instructor name: \n",
    "* Blog post URL:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This project was an exercise in multiple linear regression, using the Housing \n",
    "#dataset from King County. The process follows the OSEM-I Data Science work flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#O: Obtain Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##The first step is to upload the data and load the numpy/pandas libraries, then take a \n",
    "##look at what the dataframe looks like, inspect column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "kchouse = pd.read_csv('data/kc_house_data.csv')\n",
    "kchouse.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kchouse.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I dropped unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc_new = kchouse.drop(['date', 'view', 'sqft_above', 'sqft_basement', 'yr_renovated', 'zipcode', 'lat', 'long', 'sqft_living15', 'sqft_lot15'], axis=1)\n",
    "kc_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "corr = kc_new.corr()\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "with sns.axes_style(\"white\"):\n",
    "\n",
    "    f, ax = plt.subplots(figsize=(16, 14))\n",
    "\n",
    "    ax = sns.heatmap(corr, mask=mask, square=True, annot = True, cmap = 'coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The next steps, Scrub and Explore, do mean separate things, but tend go hand in \n",
    "#hand. As we Explore more representations of our data, we gain more particular \n",
    "#insight into its characteristics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at the basic stats of the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc_new.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some notes: # Mean price is $540,296.57 \n",
    "             # std $367368.14\n",
    "             # min $78,000.0 \n",
    "             # 25% $322,000.0\n",
    "             # 50% $450,000.0,\n",
    "             # 75% $645000.0\n",
    "             # max $7,700,000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I noticed there were null values in the waterfront column. The values 1 and 0 \n",
    "#represent if the property is on a waterfront or not. I'm making and educated \n",
    "#assumption that that means there is no waterfront, so I changed the null values \n",
    "#to a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc_new.isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc_new['waterfront'] = kc_new['waterfront'].fillna(0.0)\n",
    "kc_new.isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I wanted to make sure there was one entry per ID, and drop any double-entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc_new['id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc_new.drop_duplicates(subset = 'id', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I created a correlation heatmap to ID any potential independent variables that\n",
    "#exhibit multicolinearity, as that would violate one of the necessary assumptions\n",
    "#we need for Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "corr = kc_new.corr()\n",
    "\n",
    "f, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "ax = sns.heatmap(corr, mask=mask, center = 0, square=True, annot = True, cmap = 'coolwarm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = kc_new.corr().abs().stack().reset_index().sort_values(0, ascending=False)\n",
    "\n",
    "# zip the variable name columns (Which were only named level_0 and level_1 by default) in a new column named \"pairs\"\n",
    "df['pairs'] = list(zip(df.level_0, df.level_1))\n",
    "\n",
    "# set index to pairs\n",
    "df.set_index(['pairs'], inplace = True)\n",
    "\n",
    "#d rop level columns\n",
    "df.drop(columns=['level_1', 'level_0'], inplace = True)\n",
    "\n",
    "# rename correlation column as cc rather than 0\n",
    "df.columns = ['cc']\n",
    "\n",
    "# drop duplicates. This could be dangerous if you have variables perfectly correlated with variables other than themselves.\n",
    "# for the sake of exercise, kept it in.\n",
    "df.drop_duplicates(inplace=True)\n",
    "df[(df.cc>.75) & (df.cc <1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### big ol scatter matrix to help discern between continuous/categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(kc_new, figsize=[12,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check for outliers ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x = kc_new['bedrooms'], y = kc_new['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x = kc_new['bathrooms'], y = kc_new['price'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x = kc_new['sqft_living'], y = kc_new['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x = kc_new['sqft_lot'], y = kc_new['price'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x = kc_new['id'], y = kc_new['price'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x = kc_new['condition'], y = kc_new['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x = kc_new['floors'], y = kc_new['price'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x = kc_new['yr_built'], y = kc_new['price'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x = kc_new['grade'], y = kc_new['price'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x = kc_new['waterfront'], y = kc_new['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###****** outlier elimination *******###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from scipy import stats\n",
    "z = np.abs(stats.zscore(kc_new))\n",
    "z\n",
    "\n",
    "threshold = 4\n",
    "print(np.where(z >= 4))\n",
    "\n",
    "kc_new_out = kc_new[(z<=4).all(axis = 1)]\n",
    "kc_new_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###********************************###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous = ['price',  'sqft_lot', 'sqft_living']\n",
    "categoricals = ['waterfront', 'condition', 'grade', 'yr_built','bathrooms', 'floors','bedrooms', 'id']\n",
    "kccat = kc_new[categoricals]\n",
    "kccon = kc_new[continuous]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kccon.hist(figsize = [12,12]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### doing an initial model just for funsies ####\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "outcome = 'price'\n",
    "predictors = kc_new.drop('price', axis=1)\n",
    "pred_sum = '+'.join(predictors.columns)\n",
    "formula = outcome + '~' + pred_sum\n",
    "model = ols(formula=formula, data=kc_new).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log and normalize features\n",
    "log_names = [f'{column}_log' for column in kccon.columns]\n",
    "\n",
    "kccon_log = np.log(kccon)\n",
    "kccon_log.columns = log_names\n",
    "\n",
    "log_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kccon_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(feature):\n",
    "    return (feature - feature.mean()) / feature.std()\n",
    "\n",
    "kc_log_norm = kccon_log.apply(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc_log_norm.hist(figsize = [12,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### check features with statsmodels ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLS with Statsmodels #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ols for continuous features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = 'price_log'\n",
    "predictors = kc_log_norm.drop('price_log', axis=1)\n",
    "pred_sum = '+'.join(predictors.columns)\n",
    "formula = outcome + '~' + pred_sum\n",
    "model = ols(formula=formula, data=kc_log_norm).fit()\n",
    "model.summary()\n",
    "\n",
    "### OLS Regression Results for normalized continuous variables ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------ Categorical -------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kccat.hist(figsize = [12,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_ohe = pd.get_dummies(kccat['condition'], prefix = 'condition', drop_first=True)\n",
    "waterfront_ohe =pd.get_dummies(kccat['waterfront'], prefix = 'waterfront', drop_first=True)\n",
    "grade_ohe= pd.get_dummies(kccat['grade'], prefix = 'grade', drop_first=True)\n",
    "floors_ohe = pd.get_dummies(kccat['floors'], prefix = 'floors', drop_first=True)\n",
    "bed_ohe = pd.get_dummies(kccat['bedrooms'], prefix = 'bedrooms', drop_first=True)\n",
    "bath_ohe = pd.get_dummies(kccat['bathrooms'], prefix = 'bathrooms', drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_concat = pd.concat([condition_ohe, waterfront_ohe, grade_ohe, floors_ohe, bed_ohe, kccat['yr_built'], kccat['id'], bath_ohe], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed = pd.concat([kc_log_norm, ohe_concat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed.columns = preprocessed.columns.str.replace('.','_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###MODEL###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = 'price_log'\n",
    "predictors = preprocessed.drop('price_log', axis=1)\n",
    "pred_sum = '+'.join(predictors.columns)\n",
    "formula = outcome + '~' + pred_sum\n",
    "model = ols(formula=formula, data=preprocessed).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessed.drop('price_log', axis=1)\n",
    "y = preprocessed['price_log']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X, y)\n",
    "preds = linreg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "residuals = y - preds\n",
    "\n",
    "plt.scatter(preds, residuals)\n",
    "plt.hlines(0, preds.min(), preds.max())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import ShuffleSplit, cross_validate\n",
    "\n",
    "splitter = ShuffleSplit(n_splits=3, test_size=0.25, random_state=0)\n",
    "baseline_model = LinearRegression()\n",
    "\n",
    "baseline_scores = cross_validate(\n",
    "    estimator=baseline_model,\n",
    "    X=X,\n",
    "    y=y,\n",
    "    return_train_score=True,\n",
    "    cv=splitter\n",
    ")\n",
    "\n",
    "print(\"Train score:     \", baseline_scores[\"train_score\"].mean())\n",
    "print(\"Validation score:\", baseline_scores[\"test_score\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sm.graphics.qqplot(model.resid, dist=stats.norm, line='45', fit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "print(len(X_train), len(X_test), len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stepwise_selection(X, y, \n",
    "                       initial_list=[], \n",
    "                       threshold_in=0.01, \n",
    "                       threshold_out = 0.05, \n",
    "                       verbose=True):\n",
    "    \"\"\" \n",
    "    Perform a forward-backward feature selection \n",
    "    based on p-value from statsmodels.api.OLS\n",
    "    Arguments:\n",
    "        X - pandas.DataFrame with candidate features\n",
    "        y - list-like with the target\n",
    "        initial_list - list of features to start with (column names of X)\n",
    "        threshold_in - include a feature if its p-value < threshold_in\n",
    "        threshold_out - exclude a feature if its p-value > threshold_out\n",
    "        verbose - whether to print the sequence of inclusions and exclusions\n",
    "    Returns: list of selected features \n",
    "    Always set threshold_in < threshold_out to avoid infinite looping.\n",
    "    See https://en.wikipedia.org/wiki/Stepwise_regression for the details\n",
    "    \"\"\"\n",
    "    included = list(initial_list)\n",
    "    while True:\n",
    "        changed=False\n",
    "        # forward step\n",
    "        excluded = list(set(X.columns)-set(included))\n",
    "        new_pval = pd.Series(index=excluded, dtype='float64')\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.idxmin()\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "\n",
    "        # backward step\n",
    "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "        # use all coefs except intercept\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max() # null if pvalues is empty\n",
    "        if worst_pval > threshold_out:\n",
    "            changed=True\n",
    "            worst_feature = pvalues.idxmax()\n",
    "            included.remove(worst_feature)\n",
    "            if verbose:\n",
    "                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n",
    "        if not changed:\n",
    "            break\n",
    "    return included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X\n",
    "y = y\n",
    "\n",
    "result = stepwise_selection(X, y, verbose = True)\n",
    "print('resulting features:')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fin = X[result]\n",
    "X_with_intercept = sm.add_constant(X_fin)\n",
    "model = sm.OLS(y,X_with_intercept).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
